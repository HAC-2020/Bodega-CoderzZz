syntax = "proto3";

// python -m grpc_tools.protoc --proto_path=protos -I. --python_out=./src/. --grpc_python_out=./src/. ./protos/speech/proto_speech/audio2text.proto

/**
 *
 */
service Audio2Text {
  /**
   * Client can call this method multiple times to specify audio chunks.
   * OPUS encoding and 100ms chunk is expected.
   */
  rpc StreamingRecognize (stream StreamingRecognizeRequest) returns (stream StreamingRecognizeResponse) {}
}

// The top-level message sent by the client for the `StreamingRecognize` method.
// Multiple `StreamingRecognizeRequest` messages are sent. The first message
// must contain a `streaming_config` message and must not contain
// `audio_content`. All subsequent messages must contain `audio_content` and
// must not contain a `streaming_config` message.
message StreamingRecognizeRequest {
    // The streaming request, which is either a streaming config or audio content.
  oneof streaming_request {
    // Provides information to the recognizer that specifies how to process the
    // request. The first `StreamingRecognizeRequest` message must contain a
    // `streaming_config`  message.
    StreamingRecognitionConfig streaming_config = 1;

    // The audio data to be recognized. Sequential chunks of audio data are sent
    // in sequential `StreamingRecognizeRequest` messages. The first
    // `StreamingRecognizeRequest` message must not contain `audio_content` data
    // and all subsequent `StreamingRecognizeRequest` messages must contain
    // `audio_content` data. The audio bytes must be encoded as specified in
    // `RecognitionConfig`. Note: as with all bytes fields, proto buffers use a
    // pure binary representation (not base64). See
    // [content limits](https://cloud.google.com/speech-to-text/quotas#content).
    bytes audio_content = 2;
  }
}

// A speech recognition result corresponding to a portion of the audio.
message StreamingRecognizeResponse {
  // May contain one or more recognition hypotheses (up to the
  // maximum specified in `max_alternatives`).
  // These alternatives are ordered in terms of accuracy, with the top (first)
  // alternative being the most probable, as ranked by the recognizer.
  repeated StreamingRecognitionResult results = 1;
}

// A streaming speech recognition result corresponding to a portion of the audio
// that is currently being processed.
message StreamingRecognitionResult {
  // May contain one or more recognition hypotheses (up to the
  // maximum specified in `max_alternatives`).
  // These alternatives are ordered in terms of accuracy, with the top (first)
  // alternative being the most probable, as ranked by the recognizer.
  repeated SpeechRecognitionAlternative alternatives = 1;
}

// Alternative hypotheses (a.k.a. n-best list).
message SpeechRecognitionAlternative {
  // Transcript text representing the words that the user spoke.
  string transcript = 1;
}

// Provides information to the recognizer that specifies how to process the
// request.
message StreamingRecognitionConfig {
}